{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp.nb_data import *\n",
    "from exp.nb_model import *\n",
    "from exp.nb_all import *\n",
    "from exp.nb_Loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [into_rgb, ResizeFixed(128), to_byte_tensor, to_float_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "il = ImageList.from_files(path,image_extensions,recurse = True,tfms = tfms)\n",
    "\n",
    "ll = LabeledList.label_none(il, path/'list_attr_celeba.csv')\n",
    "\n",
    "dl = DataLoader(ll, batch_size = 32,num_workers= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBunch():\n",
    "    def __init__(self,train_dl,valid_dl = None):\n",
    "        self.train_dl = train_dl\n",
    "#         self.valid_dl = valid_dl\n",
    "#         self.c =self.train_dl.dataset.y.max().item() + 1\n",
    "\n",
    "    @property\n",
    "    def train_ds(self): return self.train_dl.dataset\n",
    "\n",
    "#     @property\n",
    "#     def valid_ds(self): return self.valid_dl.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner1():\n",
    "    def __init__(self, cbs=None, cb_funcs=None):\n",
    "        cbs = listify(cbs)\n",
    "        for cbf in listify(cb_funcs):\n",
    "            cb = cbf()\n",
    "            setattr(self, cb.name, cb)\n",
    "            cbs.append(cb)\n",
    "        self.stop,self.cbs = False,[TrainEvalCallback()]+cbs\n",
    "\n",
    "    @property\n",
    "    def opt(self):       return self.learn.opt\n",
    "    @property\n",
    "    def model(self):     return self.learn.model\n",
    "    @property\n",
    "    def loss_func(self): return self.learn.loss_func\n",
    "    @property\n",
    "    def data(self):      return self.learn.data\n",
    "\n",
    "    def one_batch(self, xb, yb):\n",
    "        try:\n",
    "            self.xb,self.yb = xb,yb\n",
    "            self('begin_batch')\n",
    "            self.pred = self.model(self.xb)\n",
    "            self('after_pred')\n",
    "            self.loss = self.loss_func(self.model,self.pred, self.yb)\n",
    "            self('after_loss')\n",
    "            if not self.in_train: return\n",
    "            self.loss.backward()\n",
    "            self('after_backward')\n",
    "            self.opt.step()\n",
    "            self('after_step')\n",
    "            self.opt.zero_grad()\n",
    "        except CancelBatchException: self('after_cancel_batch')\n",
    "        finally: self('after_batch')\n",
    "\n",
    "    def all_batches(self, dl):\n",
    "        self.iters = len(dl)\n",
    "        try:\n",
    "            for xb,yb in dl: self.one_batch(xb, yb)\n",
    "        except CancelEpochException: self('after_cancel_epoch')\n",
    "\n",
    "    def fit(self, epochs, learn):\n",
    "        self.epochs,self.learn,self.loss = epochs,learn,tensor(0.)\n",
    "\n",
    "        try:\n",
    "            for cb in self.cbs: cb.set_runner(self)\n",
    "            self('begin_fit')\n",
    "            for epoch in range(epochs):\n",
    "                self.epoch = epoch\n",
    "                if not self('begin_epoch'): self.all_batches(self.data.train_dl)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    if not self('begin_validate'): self.all_batches(self.data.valid_dl)\n",
    "                self('after_epoch')\n",
    "\n",
    "        except CancelTrainException: self('after_cancel_train')\n",
    "        finally:\n",
    "            self('after_fit')\n",
    "#             self.learn = None\n",
    "\n",
    "    def __call__(self, cb_name):\n",
    "        res = False\n",
    "        for cb in sorted(self.cbs, key=lambda x: x._order): res = cb(cb_name) or res\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kl_loss(attr,model,pred,targ):\n",
    "#     e = getattr(model,attr)\n",
    "#     return (-0.5*torch.sum(1 + e.log_var - torch.pow(e.mean,2) - torch.exp(e.log_var), axis = 1)).sum()/int(pred.shape[0])\n",
    "    \n",
    "\n",
    "# def total_loss(r_loss_factor,attr,model,pred,targ):\n",
    "#     return r_loss_factor*F.mse_loss(pred,targ) + kl_loss(attr,model,pred,targ)\n",
    "\n",
    "# class Total_loss():\n",
    "#     def __init__(self, r = 10000, attr = 'enc'):\n",
    "#         self.r = r\n",
    "#         self.a = attr\n",
    "#         self.m_loss, self.kl_loss = 0.,0.\n",
    "        \n",
    "#     def __call__(self,model,pred,targ):\n",
    "#         e = getattr(model,self.a)\n",
    "#         self.m_loss = F.mse_loss(pred,targ)\n",
    "#         self.kl_loss = (-0.5*torch.sum(1 + e.log_var - torch.pow(e.mean,2) - torch.exp(e.log_var), axis = 1)).mean()\n",
    "#         return self.r*self.m_loss + self.kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainEvalCallback(Callback):\n",
    "    _order = 1\n",
    "    def begin_fit(self):\n",
    "        self.run.n_epoch, self.run.n_iters = 0.,0.\n",
    "\n",
    "\n",
    "    def begin_epoch(self):\n",
    "        self.model.train()\n",
    "        self.run.in_train = True\n",
    "        self.run.n_epoch = self.epoch\n",
    "\n",
    "    def begin_batch(self):\n",
    "        if self.run.in_train:\n",
    "            self.run.n_epoch += 1/self.iters\n",
    "            self.run.n_iters += 1\n",
    "\n",
    "    def begin_validate(self):\n",
    "        return True\n",
    "\n",
    "class CudaCallback(Callback):\n",
    "    _order = 30\n",
    "    def begin_fit(self): self.model.cuda()\n",
    "    def begin_batch(self): self.run.xb, self.run.yb = self.xb.cuda(), self.yb.cuda()\n",
    "\n",
    "class PrintLossCallback(Callback):\n",
    "    \n",
    "    def after_loss(self):\n",
    "        if not self.n_iters%10:\n",
    "            print(f'{self.n_iters} iterations -> Perceptual={self.loss_func.ploss},Kl={self.loss_func.kl_loss}, Total={self.loss}')\n",
    "\n",
    "\n",
    "\n",
    "class ParamSchedulerCallback(Callback):\n",
    "    def __init__(self,param,sched_func):\n",
    "        self.param = param\n",
    "        self.sf = sched_func\n",
    "#         self.pos = []\n",
    "\n",
    "    def change_param(self):\n",
    "        self.po = self.run.n_epoch/self.run.epochs\n",
    "        for i in self.opt.param_groups:\n",
    "            i[self.param] = self.sf(self.po)\n",
    "#             self.pos.append(self.po)\n",
    "\n",
    "    def after_loss(self):\n",
    "        if self.in_train:\n",
    "#             print(self.run.n_epoch,self.pos)\n",
    "            self.change_param()\n",
    "\n",
    "    \n",
    "class RecorderCallback(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.lrs = []\n",
    "        self.losses = []\n",
    "\n",
    "    def after_loss(self):\n",
    "        if self.in_train:\n",
    "            self.lrs.append(self.opt.param_groups[-1]['lr'])\n",
    "            self.losses.append(self.loss.detach().cpu())\n",
    "\n",
    "    def plot_lr(self):\n",
    "        plt.plot(self.lrs)\n",
    "\n",
    "    def plot_losses(self):\n",
    "        plt.plot(self.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "    def begin_batch(self):\n",
    "        print(self.n_iters)\n",
    "        if self.n_iters > 30:\n",
    "            raise CancelTrainException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateDictCallback(Callback):\n",
    "    def __init__(self,path):\n",
    "        self.path = path\n",
    "        \n",
    "    def after_batch(self):\n",
    "        if not self.n_iters%1000:\n",
    "            torch.save(model.state_dict(), self.path + '/state_dict')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [CudaCallback,RecorderCallback,PrintLossCallback, \n",
    "       partial(StateDictCallback,'C:/Users/iamab/OneDrive/Documents/project'), TestCallback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_opt(data, enc_channels,dec_channels,bn=True,z_dim=200,enc_layer= conv_layer,dec_layer= conv_transpose_layer,\n",
    "                  opt = 'Adam', lr = 0.001,state_dict_path = None,dropout = True,**kwargs):\n",
    "    model = Variational_Autoencoder(enc_channels,dec_channels,bn = bn,z_dim=z_dim, enc_layer=enc_layer,\n",
    "                                   dec_layer=dec_layer, dropout = dropout,**kwargs)\n",
    "    op = getattr(optim, opt)\n",
    "    x = next(iter(data.train_dl))[0]\n",
    "    t = model(x)\n",
    "    del t,x\n",
    "    gc.collect()\n",
    "    if state_dict_path is not None:\n",
    "        model.load_state_dict(torch.load(state_dict_path))\n",
    "    return model, op(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,opt = get_model_opt(data, enc_channels = [32,64,64,64], dec_channels = [64,64,64,32],lr = 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learn_run(cbfs,model,opt,data,loss_func = F.cross_entropy):\n",
    "    learn = Learner(model,opt,data,loss_func)\n",
    "    run = Runner1(cb_funcs= cbfs)\n",
    "    return learn,run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(cbs,model,opt,\n",
    "                          data,loss_func= Total_loss(blocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.fit(5,learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(im, figsize=(3,3)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(im.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(il[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].detach().cpu().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = run.model(il[1][None,:].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_image(a[0].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.mse_loss(a[0].detach().cpu(), il[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model(il[18][None,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
